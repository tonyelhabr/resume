
# Terms  [^1]

[^1]: https://www.precision-analytics.ca/blog/a-gentle-inla-tutorial/

+ Markov-chain Monte Carlo (MCMC)

+ Hierarchal models
  + widely used across disciplines to represent complex dependency structures in data. Uncertainty in model parameters and latent variables or processes can be encoded with appropriate prior distributions using a Bayesian framework

+ Credible interval vs. Confidence interval

+ Bayesian vs. frequentist
  + Bayesian
    + generally want posterior distributions for our models (e.g., the distribution of the parameters given the data
    + posterior distribution is equal to the data likelihood multiplied by the priors over the normalizing constant (so the posterior integrates to one)
  + Frequentist
    + often maximize the data likelihood using numerical methods like Newton-Raphson to obtain a point estimate for a given parameter (which we view as fixed but unknown), and use the idea of theoretical resampling to estimate a corresponding confidence interval around that parameter estimate


+ Conjugate priors
  + canonical pairs of distributions that simplify Bayesian analysis

# Neural Networks

## ["Epoch vs Batch Size vs Iterations"](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)

"To find out the difference between these terms you need to know some of the machine learning terms like Gradient Descent to help you better understand."

"It is an ***iterative*** optimization algorithm used in machine learning to find the best results (minima of a curve). *Gradient* means the rate of inclination or declination of a slope. *Descent* means the instance of descending. The algorithm is iterative means that we need to get the results multiple times to get the most optimal result."

"We need terminologies like epochs, batch size, iterations only when the data is too big which happens all the time in machine learning and we can’t pass all the data to the computer at once. So, to overcome this problem we need to divide the data into smaller sizes and give it to our computer one by one and update the weights of the neural networks at the end of every step to fit it to the data given."

+ Epoch: "One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE."
  + "[U]pdating the weights with single pass or one epoch is not enough... As the number of epochs increases, more number of times the weight are changed in the neural network and the curve goes from underfitting to optimal to overfitting curve."
  + There is no right answer to the question "What is the right number of epochs?"

+ Batch size: "Total number of training examples present in a single batch."
  + "Batch size and number of batches are two different things."

+ Iterations: "the number of batches needed to complete on epoch"
  + "The number of batches is equal to the number of iterations for one epoch."
  + e.g. "We can divide the dataset of 2000 examples into batches of 500 then it will take 4 iterations to complete 1 epoch."
  
  ## ["Difference Between a Batch and an Epoch in a Neural Network"](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)

+ "Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model."
+ "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated."
+ "The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset."

# WP

## [`{ncaahoopR}`](https://github.com/lbenz730/ncaahoopR)

+ [`wp_compute` function](https://github.com/lbenz730/ncaahoopR/blob/ff96048788f943a339645d5e004e2f05a97d8e02/R/helpers.R)
    + log(odds) ~ score difference | seconds remaining * score difference + favored by | seconds remaining * seconds_remaining

## [`{nflscrapR}`](https://github.com/maksimhorowitz/nflscrapR)

+ `mgcv::bam()`

# Expected Points

## ["nflWAR: A Reproducible Method for Offensive Player Evaluation in Football" (Extended Edition)](https://arxiv.org/pdf/1802.00998.pdf)

+ "To estimate the probabilities of each possible scoring event conditional on the current game situation, we use multinomial logistic regression. For each play, we find the next scoring event within the same half (with respect to the possession team) as one of the seven possible events: touchdown (7 points), field goal (3 points), safety (2 points), no score (0 points), opponent safety (-2 points), opponent field goal (-3 points), and opponent touchdown (-7 points). Here, we ignore point after touchdown (PAT) attempts, and we treat PATs separately"

| Variable | Variable description                                                         |
|----------|------------------------------------------------------------------------------|
| Down     | The current down (1st, 2nd, 3rd, or 4th)                                     |
| Seconds  | Number of seconds remaining in half                                          |
| Yardline | Yards from endzone (0 to 100)                                                |
| log(YTG) | Log transformation of yards to go for a first down                           |
| GTG      | Indicator for whether or not it is a goal down situation                     |
| UTM      | Indicator for whether or not time remaining in the half is under two minutes |

### [`{nflscrapR}`](https://github.com/maksimhorowitz/nflscrapR)

+ [`calculate_expected_points()` function](https://github.com/maksimhorowitz/nflscrapR/blob/23849e24d03a0450ffd0eb9c3684bc66bc46725b/R/ep_wp_calculator.R)
  + `ep = (0 * no_score_prob) + (-fg_value * opp_fg_prob) + (-safety_value * opp_safety_prob) + (-td_value * opp_td_prob) + (fg_value * fg_prob) + (safety_value * safety_prob) + (td_value * td_prob)`

# Personal Experience

# ["OptaPro Analytics Forum 2018 - Luke Bornn Guest Talk"](https://www.youtube.com/watch?v=hirA6p42_pM)

+ Data Visualization as a tool
  + Learn to communicate statistical ideas visually
  + "Presenting raw information is usually the easiest path, but it's almost never the best path... Once we presented [it in a better way (visually)], then not only wanted the charts, but also the raw numbers once they understood the concept..."
  + "Think carefully abou data visualization. How do the people that you are presenting to actually think about the underlying problem, and how do you turn the data into that?" "
  + "Communicate on the levels [on which your audience thinks]."
  + "Often times you need to metaphors and analogies."

+ "Don't let the data dictate the analysis. Instead, if you're trying to solve a problem, admit the limitations of the data... Don't frame the problem in terms of the data that you have; frame the problem, then re-admit the limitations and assumptions that you have to make given the data that you have... this will allow you to convey the information a lot more clearly and better address the issues.

# 2019 NESSIS

## Favorite Presentations

### ["Extracting Player Tracking Data from Video Using Non-Stationary Cameras and a Combination of Computer Vision Techniques"](https://drive.google.com/uc?id=1BhFbAPDxKe2oxYen_qARJJ5kM3-WL5Fj&export=download), Neil Johnson, ESPN Analytics

[YouTube video](https://www.youtube.com/watch?v=tvVXl0f45Rc&feature=youtu.be)

### ["Unsupervised Run Type Detection"](http://nessis.org/nessis19/Sam-Gregory.pptx), Sam Gregory, Sportlogiq

[YouTube video](https://www.youtube.com/watch?v=Z4Q7JBMu8m4&feature=youtu.be)

### “Classifying and Analyzing Team Strategy in Professional Soccer Matches” by Laurie Shaw

[YouTube video](https://www.youtube.com/watch?v=VU4BOu6VfbU&feature=youtu.be)

### ["Going Deep: Models for Continuous-Time Within-Play Valuation of Game Outcomes in American Football with Tracking Data"](https://docs.google.com/presentation/d/1j1CzZncIFBtP0qjnStcD505JSxvv3q5XejP0QtWsE_o/edit#slide=id.p), Ron Yurko, Carnegie Mellon University

[YouTube video](https://www.youtube.com/watch?v=JKfdPe0PkEY&feature=youtu.be)

+ Play-by-play evaluation with `{nflscrapR}`
 + Expected points (EP): how many points have teams scored in similar situations?
  + Multinomial logistic regression
 + Win probability (WP): have teams in similar situations won the game?
  + Generalized additive model (GAM)
 
 + What about continuous, within play value?

+ Continuous-time valuation with player-tracking data

 + Cervone et. al. (2014, 2016), two-level Markov chain approach
 + Soccer extensions: Link et. al. (2016), Fernandez et. al (2019)

+ Continuous-time play value framework
 + **GOAL**: For each play $i \in n$, model the end-of-play yard line $Y_i^\star$
  + $t > 0$: time between start (i.e. snap) and end of play)
  + $\mathcal{F}(X_{t,i})$: filtration of ball and player locations, trajectories, etc. until $t$
  + $\mathbb{E}[Y_{t,i}^\star | \mathcal{F}(X_{t,i})$: expected end-of-play yard line at time $t$.

+ General framework

![](model-yurko.png)

+ Ball-carrier model

 + We model the **yards gained** $Y_{t,i}$ from the current position on the field at $t$: $\mathbb{E}[Y_{t,i} | \mathcal{F}(X_{t,i}) = f(\mathcal{F}(X_{t,i}))$
 + Use the fact that $Y_{t,i}^\star = Y_{t,i} + \text{ [player’s current yard line] }$
 + Then by linearity of expectations,$\mathbb{E}[Y_{t,i}^\star | \mathcal{F}(X_{t,i}) = \mathbb{E}[Y_{t,i} | \mathcal{F}(X_{t,i})] + \text{ [player’s current yard line] }$ 

+ Model validation
 + Leave-one-week-out (LOWO) cross-validation, i.e. train on weeks 1-5, get frame predictions for week 6
 + Criteria for hold-out predictions:
  + Overall holdout root mean-squared error (RMSE)
  + Error across ball-carrier sequence

+ LSTM displays best LOWO CV results

### ["Route Identification in the National Football League"](https://docs.google.com/presentation/d/1Q8CSdB7YJn9jvvnDJBG-o3tKy8LnpodmdIK8ZxiatPI/edit#slide=id.g54c124210e_0_0) (best viewed in "presentation mode"), Dani Chu, Simon Fraser University

[YouTube video](https://www.youtube.com/watch?v=rnAzURpLLbs&feature=youtu.be)

+ Bezier Curve

 + Defined on $t_i \in [0, 1]$ with control point $\theta$. In 2 dimensions and degree 9 ...


+ Curve Clustering
 + Assume 
  + There are K route types
  + Player trajectories are realizations of one of the K routes 
  + Route types are specified by a Bezier Curve
 + Then
  + Use the Expectation Maximization (EM) algorithm to
  + Learn the template curves 
  + Label probabilities for each observed trajectory 


### ["How Do Typical Runners' Performances Vary with Age and Gender?"](http://nessis.org/nessis19/Richard-Smith.pdf), Richard Smith, University of North Carolina, Chapel Hill

[YouTube video](https://www.youtube.com/watch?v=oNnkeB0T3II&feature=youtu.be)

# EPV

## ["Decomposing	the	Immeasurable	Sport: A	deep	learning	expected	possession	value	framework	 for soccer"](http://www.lukebornn.com/papers/fernandez_sloan_2019.pdf)

"While	 our	 aim	 is	 similar	 to	 that	 of	 the	 expected	
possession	 value	 (EPV)	 approach	in	 basketball	 [1],	 our	 focus	 on	 soccer	 necessitates	 a	 drastically	
different	approach	to	account	for	the	nuances	of	the	sport,	such	as	looser	notions	of	possession,	the	
ability	 of	 passes	 and	 drives	 to	 happen	 at	 any	 location,	 and	 space-time	 dependent	 turnover	
evaluation.	"

"We	define	expected	possession	value	(EPV)	as	the	expected	outcome	of	a	soccer	possession	based	
on	the	full	resolution	spatiotemporal	data.	EPV	is	a	real	number	in	the	[-1, 1]	range,	expressing	the	
likelihood	 of	 a	 possession	 ending	in	 a	 goal	 for	 the	 attacking	 team	 (1)	 or	 a	 goal	 by	 the	 defending	
team	(-1)	after	an	immediate	possession	regain.	Similarly	to	the	EPV	approach	for	basketball	[1,	2]	
our	model	provides	a	frame	by	frame	estimation	of	the	outcome	of	the	possession,	acting	as	a	stock	
ticker	for	the	expected	outcome	of	a	possession.	Aside	from	a	shared	high-level	goal,	however,	our	
approach	 is	 drastically	 different,	 driven	 by	 the	 underlying	 differences	 in	 the	 two	 sports.	 As	 one	
concrete	example,	in	soccer	we	cannot	assume	that	passes	are	played	directly	to	a	player’s	location,	
as	 the	ball	can	be	played	into	open	space	in	 front	of	or	behind	the	intended	receiver;	as	such,	we	
need	 to	consider	 the	 full	space	of	potential	destination	locations.	As	another	example,	 there	is	no	
time	limit	 for	soccer	possessions	(aside	 from	the	45	minute	half),	with complex	and	often	blurred	
dynamics	between	offense	and	defense."

"Recent work in soccer analytics has provided powerful models for inspecting a variety of specific game situations, including pass risk and quality [3], attacking shot danger [4], and off-ball  positioning in shooting opportunities [5]. While being successful in the specific task they resolve,  there is no clear path on how we could join these models together into a more comprehensive  framework of analysis. Other approaches make use of Markov processes to correlate sequence of  events within possession sequences with the probability of scoring [6, 7, 8], providing a similar  overall objective of that of EPV but with lower interpretability capabilities than the presented model. Here, we propose a decoupled model for EPV that decomposes goal value into the expected values of different actions that further the possession, along with the probabilities of these actions. Equation (1) presents EPV, the expected outcome of the possession given all the spatiotemporal information at time $t$ ($T_t$) as the composition of independent models for three main types of actions ($A$): passes ($\rho$), shots ($\zeta$) and ball-drives ($\delta$) Different sets of these components are estimated independently, such as the value surface for passes, the value surface for ball-drives, the likelihood of one of these events taking place, and the expectation of goals for shots."

$$
\begin{array}{ccl}
EPV(t) & = & \mathrm{E}[X | T_t] \\
& = & \mathrm{E}[X | A=\rho] \mathrm{P}(A=\rho)+\mathrm{E}[X | A=\zeta] \mathrm{P}(+\mathrm{E}[X | A=\delta] \mathrm{P}(A=\delta)
\end{array}
$$

where

+ $\mathrm{E}[X | A=\rho]$ is the passing value surface dependent on destination location
+ $\mathrm{E}[X | A=\zeta]$ is the expected goals model
+ $\mathrm{E}[X | A=\delta]$ is the drive value surface dependent on destination location
+ $\mathrm{P}(A)$ are the action likelihood models


"Each	 of	 the	 model	 components	 is	 estimated	 independently	 through	 machine	 learning	
algorithms	 based on	 a	 wide	 set	 of	 spatiotemporal	 features.	 Pass	 and	 turnover	 probabilities	 are	
estimated	 using	 logistic	 regression.	 Action	 likelihood	 is	 modeled	 through	 a	 convolutional	 neural	
network	on	top	of	pitch	control	and	pitch	influence	surfaces	based	on	a	recent	statistical	model	for	
pitch	control	[9].	Pass	and	ball-drive	value	expectation	are	learned	from	a	set	of	carefully	designed	
deep	 neural	 networks.
...
Recently,	neural	networks	have	been	explored	in	a	
similar	context	[10],	by	estimating	player	positioning	and	probability	of	reaching	certain	locations	
on	the	field,	which	is	fundamentally	different	from	the	objectives	of	our	approach.	For	the	purposes	
of	this	paper	we	focus	not	on	the	technical	details,	but	rather	the	power	of	the	decoupled	modeling	
framework	in	answering	many	important	questions	previously	unanswered	by	the	soccer	analytics	
community.	 "

## ["POINTWISE: Predicting Points and Valuing Decisions in Real Time with NBA Optical Tracking Data" Paper](http://www.lukebornn.com/papers/cervone_ssac_2014.pdf)

+ Abstract: "Basketball is a game of decisions; at any moment, a player can change the character of a possession by choosing to pass, dribble, or shoot. The current state of basketball analytics, however, provides no way to quantitatively evaluate the vast majority of decisions that players make, as most metrics are driven by events that occur at or near the end of a possession, such as points, turnovers, and assists. We propose a framework for using player-tracking data to assign a point value to each moment of a possession by computing how many points the offense is expected to score by the end of the possession, a quantity we call expected possession value (EPV). EPV allows analysts to evaluate every decision made during a basketball game – whether it is to pass, dribble, or shoot – opening the door for a multitude of new metrics and analyses of basketball that quantify value in terms of points."

"The major obstacle to closing this gap is the current inability to evaluate the individual tactical decisions that form the substructure of every possession of every basketball game. For example, there is no current method to estimate the value of a dribble penetration or to compare the option of taking a contested shot to the option of passing to an
open teammate."

"In this paper, we propose and implement a framework that removes this obstacle. Using player-tracking data, we develop a coherent, quantitative representation of a whole possession that summarizes each moment of the possession in terms of the number of points the offense is expected to score – a quantity we call expected possession value, or EPV... We accomplish this by specifying and fitting a probabilistic model that encodes how ball handlers make decisions based on the spatial configuration of the players on the court. EPV assigns a point value to every tactical option available to a player at each moment of a possession, allowing analysts to evaluate each decision that a player makes. For example, passing to a wide open shooter in the corner or near the basket is worth more expected points than to a covered player in a similar place."

"EPV is a conditional expectation – the expected number of points the offense will score, given the spatial configuration of the players and ball at time during the possession ($d_t$): $\text{EPV} = E[\text{points} | d_t]$.

"By definition, the current EPV of a possession is the weighted average of the outcomes of all future paths that the possession could take. Calculating this requires a model that defines a probability distribution over what the ballhandler is likely to do next, given the spatial configuration of the players on the court, as we need to understand what future paths the possession can take and how likely they are given the present state. We call this model the possession model. Using a Markovian assumption[---we assume that the decision the ballhandler makes depends only on the current spatial configuration of the possession---]the possession model allows us to estimate both (a) the probability that a player will make a particular decision in a given situation and (b) the resulting EPV of the possession after the player makes that decision. Taken together, we learn both how valuable any moment in a possession is, as well as the features of the offense's configuration that produce this value."

"Our possession model breaks down a player's options into discrete actions that may take several seconds to complete (e.g., passing or shooting) or continuous actions that evolve instantaneously (e.g., moving to the left or right). We call the former actions macrotransitions and the latter actions microtransitions. Using this breakdown, we can rewrite EPV at time during a possession by conditioning on the ballhandler's next action during a small time
window ($\epsilon$):"

$$
\begin{array}{cclr}
EPV(t) & = & E[\text{points} | d_t] \\
& = & E[\text{points} | \text{macro in } (t, t + \epsilon), d_t] P( \text{macro in } (t, t + \epsilon) | d_t) + \\
& & E[\text{points} | \text{micro in } (t, t + \epsilon), d_t] P( \text{micro in } (t, t + \epsilon) | d_t) & (1)
\end{array}
$$


"In our current implementation, we define passes, shots, and turnovers as macrotransitions, and all movements that players make with the ball as microtransitions."

"The macro/microtransition dichotomy facilitates calculating components of (1) using statistical models. The macrotransition probabilities $P( \text{macro in } (t, t + \epsilon) | d_t)$ (e.g., the instantaneous probability that a player will pass or shoot the ball) respond to the full-resolution spatial configuration of the players, and are therefore the most nuanced components. We compute these using competing risks, a statistical framework for modeling the occurrence of discrete events in continuous time, incorporating situational covariates (e.g., presence of defender between player and teammate), and spatially-smoothed random effects that capture individual players' tendencies. We compute $E[\text{points} | \text{macro in } (t, t + \epsilon), d_t]$ by modeling a coarsened version of the court space as a homogeneous Markov chain (a common technique in baseball [6] and football [7]). We compute the final components in (1), based on microtransitions, from the macrotransition components and some basic mathematical assumptions of local space-time smoothness."

## ["A Multiresolution Stochastic Process Model for Predicting Basketball Possession Outcomes"](https://arxiv.org/pdf/1408.0777v3.pdf)

# xG

### ["Premier League Projections and New Expected Goals" Article](https://cartilagefreecaptain.sbnation.com/2015/10/19/9295905/premier-league-projections-and-new-expected-goals)

+ Definition (brief):
 + "Expected goals is a method for estimating the quality of chances that a football team creates or concedes in a match. This is the thing I like a lot about xG. It may take a lot of data crunching to create specific xG values, but the underlying idea makes football sense. How many good chances did a team create?"
 
+ Inputs (brief):
 + distance (to goal)
 + angle (to goal)
 + type of pass
  + cross
  + throughball
  + etc.
 + type of play leading to shot
  + set play
  + counterattack
  + establish possession
  + etc.

+ Formula for "Regular Shots"
 + log(`goals`) = 
 (
 -3.19 
 - 0.095 * `distance` 
 + 3.18 * `inverse_distance` 
 + 1.88 * `relative_angle` 
 + 0.24 * `inverse_angle` 
 - 2.09 * `inverse_dist*angle` 
 + 0.45 * throughball_assist 
 + 0.64 * throughball_2nd_assist
 + 0.31 * assist_across_face 
 - 0.15 * cutback_assist 
 + 2.18 * inverse_assist_distance 
 + 0.12 * assist_angle 
 + 0.23 * fast_break 
 + 0.18 * counterattack 
 + 0.09 * established_possession 
 - 0.18 * following_corner 
 + 1.2 * big_chance 
 + 1.1 * following_error 
 + 0.39 * following_dribble 
 + 0.14 * dribble_distance 
 + 0.37 * rebound 
 + 0.03 * game_state 
 + 0.07 * Bundesliga 
 - 0.1 * EPL 
 - 0.09 * LaLiga 
 - 0.07 * SerieA
 )
 
+ There are separate formulas for
 + regular shots
 + headed shots assisted by crosses
 + non-headed shots assisted by crosses
 + headed shots not assisted by crosses
 + shots from direct free kicks
 + shots following a dribble of the keeper
 
+ Evaluation:
 + Used 2010-20111 through 2013-2014 data ffor big five leagues for training data.
 + Used 2014-2105 data from big five leagues for testing data.
 + RMSE of 0.258 on in-sample data and out-of sample data.
 + R^2 for Ligue 1 was notably lower compared to the other leagues.

## ["Soccer Showcase: Expected Goals, Explained" YouTube Video ](https://www.youtube.com/watch?v=mPTno8tDCbs) (Uploaded 8/28/2018)

+ Inputs:
 + distance (to goal)
 + big_chance
  + "A situation where a player should reasonable be expected to score usually in a one-on-one scenario or from very close range."
 + directness
 + assist_dist
 + dribble
 + rebound
 + assist_angle
 + counterattack
 + error
 + throughball
 + angle (to goal)
 
+ Inuition:
 + Provides an estimate the quality of the scoring opportunity
 + "What is the likelihood that a shot from this location and in this game situtation will be scored?"
  + location + situtation = xG

| lowers xG  | raises xG              |
|--------------|-------------------------------------|
| crosses   | throughballs            |
| corner kicks | square balls inside the 18-yard box |
|       | completed dribbles         |
|       | counterattacks           |
